{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Now You Code 2: Information Extraction\n\nHow do we make computers seem intelligent? One approach is to use *term extraction*. Term extration is a type of information extration where we attempt to find relevant terms in text. The relevant terms come from a *corpus*, or set of plausible terms we want to extract.\n\nFor example, suppose we have the text:\n\n`One day I would like to visit Syracuse`\n\nWe as smart humans can be fairly confident that `Syracuse` is a place, more specifically a `city`. \n\nA rudimentary method to make the computer interpret `Syracuse` as a place is to provide a corpus of cities and have the computer look up `Syracuse` in that corpus. \n\nIn this code exercise we will do just that. Let's first write a function to read cities from the file `NYC2-cities.txt` into a corpus of cities, which will be represented in Python as a list.\n\nThen write a main program loop to input some text, split the text into a list of words and if any of the words match a city in the corpus list we will output the word is a city.\n\nThe program should handle upper / lower case matching. A good approach is to title case the input. \n\nIMPORTANT: Please note that our program will ONLY work for one word cities, like `Syracuse` and will not work for multiple-word cities like `San Diego`. Don't worry about that now. \n\nSAMPLE RUN\n\n```\nEnter some text (or ENTER to quit): one day I would like to visit syracuse and rochester\nSyracuse is a city\nRochester is a city\nEnter some text (or ENTER to quit): austin is in texas\nAustin is a city\nEnter some text (or ENTER to quit): \nQuitting...\n```\n\nOnce again we will solve this problem using the problem simplification approach. First we will write the `load_city_corpus` function to build our city list. Second we will write the  `is_a_city` function which given a word and a city list will return `True` when the word is a city. Finally we conclude with the main program which finds cities in our text, as demonstrated in our sample run."
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Step 1: Problem Analysis for `load_city_corpus`\n\nInputs: None (reads from a file)\n\nOutputs: a Python list of cities\n\nAlgorithm (Steps in Program):\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Step 2: write the defintion for the load_city_corpus function\ndef load_city_corpus():\n    corpus=[]\n    with open('NYC2-cities.txt') as f:\n        for line in f:\n            corpus.append(line.strip())\n    return corpus\n\ncityList=load_city_corpus()\n\nprint(cityList)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['New York', 'Los Angeles', 'Chicago', 'Houston', 'Philadelphia', 'Phoenix', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville', 'San Francisco', 'Indianapolis', 'Columbus', 'Fort Worth', 'Charlotte', 'Seattle', 'El Paso', 'Detroit', 'Denver', 'Washington', 'Memphis', 'Boston', 'Nashville', 'Baltimore', 'Oklahoma City', 'Portland', 'Las Vegas', 'Louisville', 'Milwaukee', 'Albuquerque', 'Tucson', 'Fresno', 'Sacramento', 'Long Beach', 'Kansas City', 'Mesa', 'Atlanta', 'Virginia Beach', 'Omaha', 'Colorado Springs', 'Raleigh', 'Miami', 'Oakland', 'Minneapolis', 'Tulsa', 'Cleveland', 'Wichita', 'New Orleans', 'Arlington', 'Bakersfield', 'Tampa', 'Aurora', 'Honolulu', 'Anaheim', 'Santa Ana', 'Corpus Christi', 'Riverside', 'St. Louis', 'Lexington', 'Pittsburgh', 'Stockton', 'Anchorage', 'Cincinnati', 'Saint Paul', 'Greensboro', 'Toledo', 'Newark', 'Plano', 'Henderson', 'Lincoln', 'Orlando', 'Jersey City', 'Chula Vista', 'Buffalo', 'Fort Wayne', 'Chandler', 'St. Petersburg', 'Laredo', 'Durham', 'Irvine', 'Madison', 'Norfolk', 'Lubbock', 'Gilbert', 'Winstonâ€“Salem', 'Glendale', 'Reno', 'Hialeah', 'Garland', 'Chesapeake', 'Irving', 'North Las Vegas', 'Scottsdale', 'Baton Rouge', 'Fremont', 'Richmond', 'Boise', 'San Bernardino', 'Birmingham', 'Spokane', 'Rochester', 'Modesto', 'Des Moines', 'Oxnard', 'Tacoma', 'Fontana', 'Fayetteville', 'Moreno Valley', 'Columbus', 'Huntington Beach', 'Yonkers', 'Montgomery', 'Aurora', 'Glendale', 'Shreveport', 'Akron', 'Little Rock', 'Amarillo', 'Augusta', 'Mobile', 'Grand Rapids', 'Salt Lake City', 'Huntsville', 'Tallahassee', 'Grand Prairie', 'Overland Park', 'Knoxville', 'Brownsville', 'Worcester', 'Newport News', 'Santa Clarita', 'Providence', 'Fort Lauderdale', 'Garden Grove', 'Oceanside', 'Rancho Cucamonga', 'Santa Rosa', 'Port St. Lucie', 'Chattanooga', 'Tempe', 'Jackson', 'Cape Coral', 'Vancouver', 'Ontario', 'Sioux Falls', 'Peoria', 'Springfield', 'Pembroke Pines', 'Elk Grove', 'Salem', 'Corona', 'Lancaster', 'Eugene', 'Palmdale', 'McKinney', 'Salinas', 'Fort Collins', 'Cary', 'Hayward', 'Springfield', 'Pasadena', 'Macon', 'Pomona', 'Alexandria', 'Escondido', 'Sunnyvale', 'Lakewood', 'Kansas City', 'Rockford', 'Torrance', 'Hollywood', 'Joliet', 'Bridgeport', 'Clarksville', 'Paterson', 'Naperville', 'Frisco', 'Mesquite', 'Savannah', 'Syracuse', 'Dayton', 'Pasadena', 'Orange', 'Fullerton', 'McAllen', 'Killeen', 'Hampton', 'Bellevue', 'Warren', 'Miramar', 'West Valley City', 'Olathe', 'Columbia', 'Sterling Heights', 'Thornton', 'New Haven', 'Waco', 'Charleston', 'Thousand Oaks', 'Visalia', 'Cedar Rapids', 'Elizabeth', 'Roseville', 'Gainesville', 'Carrollton', 'Stamford', 'Denton', 'Midland', 'Coral Springs', 'Concord', 'Topeka', 'Simi Valley', 'Surprise', 'Lafayette', 'Kent', 'Hartford', 'Santa Clara', 'Victorville', 'Abilene', 'Murfreesboro', 'Evansville', 'Vallejo', 'Athens', 'Allentown', 'Berkeley', 'Norman', 'Ann Arbor', 'Beaumont', 'Independence', 'Columbia', 'Springfield', 'El Monte', 'Fargo', 'Peoria', 'Provo', 'Lansing', 'Odessa', 'Downey', 'Wilmington', 'Arvada', 'Costa Mesa', 'Round Rock', 'Carlsbad', 'Miami Gardens', 'Westminster', 'Inglewood', 'Rochester', 'Fairfield', 'Elgin', 'West Jordan', 'Clearwater', 'Manchester', 'Lowell', 'Gresham', 'Cambridge', 'Ventura', 'Temecula', 'Waterbury', 'Antioch', 'Billings', 'High Point', 'Richardson', 'Richmond', 'West Covina', 'Pueblo', 'Murrieta', 'Centennial', 'Norwalk', 'North Charleston', 'Everett', 'Pompano Beach', 'Daly City', 'Palm Bay', 'Burbank', 'Wichita Falls', 'Boulder', 'Green Bay', 'Broken Arrow', 'West Palm Beach', 'College Station', 'Pearland', 'Santa Maria', 'El Cajon', 'San Mateo', 'Lewisville', 'Rialto', 'Davenport', 'Lakeland', 'Clovis', 'Edison', 'Sandy Springs', 'Tyler', 'Las Cruces', 'South Bend', 'Woodbridge', 'Erie']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 3: Problem Analysis for `is_a_city`\n\nInputs: a string word and a Python list of cities\n\nOutputs: True or False when word is in the list of cities.\n\nAlgorithm (Steps in Program):\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Step 4: write the definition for the is_a_city function\ndef is_a_city (word,city_corpus):\n    for city in city_list:\n     if word == city: \n        return True\n    return False",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 5: Problem Analysis for entire program\n\nInputs:\n\nOutputs:\n\nAlgorithm (Steps in Program): (make sure to use the two functions we created)\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def load_city_corpus():\n    corpus=[]\n    with open('NYC2-cities.txt') as f:\n        for line in f:\n            corpus.append(line.strip())\n    return corpus\n\ncityList=load_city_corpus()\n\nword = input(\"enter some text\")\nif word == cityList:  \n    print(\"is a city\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Step 7: Questions\n\n1. Explain your approach to solving this problem for cities with 2 words like `New York` or `Los Angeles`?\n\nAnswer:\n\n\n2. How would you solve the problem where you enter a city name which is not in the corpus?\n\nAnswer:\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 8: Reflection\n\nReflect upon your experience completing this assignment. This should be a personal narrative, in your own voice, and cite specifics relevant to the activity as to help the grader understand how you arrived at the code you submitted. Things to consider touching upon: Elaborate on the process itself. Did your original problem analysis work as designed?  How many iterations did you go through before you arrived at the solution? Where did you struggle along the way and how did you overcome it? What did you learn from completing the assignment? What do you need to work on to get better? What was most valuable and least valuable about this exercise? Do you have any suggestions for improvements?\n\nTo make a good reflection, you should journal your thoughts, questions and comments while you complete the exercise.\n\nKeep your response to between 100 and 250 words.\n\n`--== Write Your Reflection Below Here ==--`\n\n"
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}